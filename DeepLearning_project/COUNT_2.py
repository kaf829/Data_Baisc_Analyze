⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.0, opt=adam, layers=1
172/172 [==============================] - 7s 39ms/step
✅2번째 Done → MAE: 0.3338
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.0, opt=adam, layers=2
172/172 [==============================] - 13s 71ms/step
✅3번째 Done → MAE: 0.3369
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.0, opt=adam, layers=3
172/172 [==============================] - 21s 117ms/step
✅4번째 Done → MAE: 0.3526
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.0, opt=rmsprop, layers=1
172/172 [==============================] - 7s 38ms/step
✅5번째 Done → MAE: 0.3437
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.0, opt=rmsprop, layers=2
172/172 [==============================] - 13s 72ms/step
✅6번째 Done → MAE: 0.3377
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.0, opt=rmsprop, layers=3
172/172 [==============================] - 20s 115ms/step
✅7번째 Done → MAE: 0.3735
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.25, opt=adam, layers=1
172/172 [==============================] - 7s 38ms/step
✅8번째 Done → MAE: 0.3489
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.25, opt=adam, layers=2
172/172 [==============================] - 13s 71ms/step
✅9번째 Done → MAE: 0.3522
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.25, opt=adam, layers=3
172/172 [==============================] - 21s 121ms/step
✅10번째 Done → MAE: 0.3396
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.25, opt=rmsprop, layers=1
172/172 [==============================] - 7s 38ms/step
✅11번째 Done → MAE: 0.3759
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.25, opt=rmsprop, layers=2
172/172 [==============================] - 13s 73ms/step
✅12번째 Done → MAE: 0.3473
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.25, opt=rmsprop, layers=3
172/172 [==============================] - 21s 122ms/step
✅13번째 Done → MAE: 0.3460
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.5, opt=adam, layers=1
172/172 [==============================] - 7s 40ms/step
✅14번째 Done → MAE: 0.3564
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.5, opt=adam, layers=2
172/172 [==============================] - 13s 76ms/step
✅15번째 Done → MAE: 0.3440
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.5, opt=adam, layers=3
172/172 [==============================] - 23s 130ms/step
✅16번째 Done → MAE: 0.3448
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.5, opt=rmsprop, layers=1
172/172 [==============================] - 12s 57ms/step
✅17번째 Done → MAE: 0.3802
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.5, opt=rmsprop, layers=2
172/172 [==============================] - 19s 108ms/step
✅18번째 Done → MAE: 0.3543
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=10, dropout=0.5, opt=rmsprop, layers=3
172/172 [==============================] - 38s 218ms/step
✅19번째 Done → MAE: 0.3696
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=30, dropout=0.0, opt=adam, layers=1
172/172 [==============================] - 10s 59ms/step
✅20번째 Done → MAE: 0.3317
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=30, dropout=0.0, opt=adam, layers=2
172/172 [==============================] - 21s 117ms/step
✅21번째 Done → MAE: 0.3423
⏳ Training LSTM: look_back=1440, units=32, batch=32, epochs=30, dropout=0.0, opt=adam, layers=3