{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dc33401-bbb6-4e7b-ae0a-ed5479a3f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        x[idx] = float(tmp_val) - delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2 * delta_x)\n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "    return grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1918cfb-23c6-41a8-9a95-c2c862e478a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "        self.name = gate_name  # 게이트 이름 (예: XOR, AND 등)\n",
    "\n",
    "        # 입력 데이터와 정답 데이터를 reshape 해서 내부에 저장\n",
    "        self.xdata = xdata.reshape(4, 2)   # 입력: 4개 샘플, 각 샘플은 2개의 입력\n",
    "        self.tdata = tdata.reshape(4, 1)   # 정답: 4개 샘플, 각 정답은 1개의 출력\n",
    "\n",
    "        # 은닉층 가중치(2입력 -> 6노드)와 편향 초기화\n",
    "        self.W2 = np.random.rand(2, 6)\n",
    "        self.b2 = np.random.rand(6)\n",
    "\n",
    "        # 출력층 가중치(6노드 -> 1출력)와 편향 초기화\n",
    "        self.W3 = np.random.rand(6, 1)\n",
    "        self.b3 = np.random.rand(1)\n",
    "\n",
    "        # 학습률 설정\n",
    "        self.learning_rate = 1e-2\n",
    "\n",
    "    def loss_val(self):\n",
    "        # 손실 함수 계산 (Cross Entropy)\n",
    "        delta = 1e-7  # 로그 안정화를 위한 작은 값\n",
    "\n",
    "        # 순전파 계산\n",
    "        z2 = np.dot(self.xdata, self.W2) + self.b2  # 은닉층 선형 결합\n",
    "        a2 = sigmoid(z2)                            # 은닉층 활성화\n",
    "        z3 = np.dot(a2, self.W3) + self.b3          # 출력층 선형 결합\n",
    "        y = a3 = sigmoid(z3)                        # 출력값 (시그모이드)\n",
    "\n",
    "        # 크로스 엔트로피 손실 계산\n",
    "        return -np.sum(\n",
    "            self.tdata * np.log(y + delta) + \n",
    "            (1 - self.tdata) * np.log(1 - y + delta)\n",
    "        )\n",
    "\n",
    "    def train(self):\n",
    "        # 손실값을 기준으로 기울기를 구할 함수 정의 (입력 x는 사용 안 함)\n",
    "        f = lambda x: self.loss_val()\n",
    "\n",
    "        # 2만 번 반복 학습\n",
    "        for step in range(20001):\n",
    "            # 기울기 계산 및 파라미터 갱신\n",
    "            self.W2 -= self.learning_rate * numerical_derivative(f, self.W2)\n",
    "            self.b2 -= self.learning_rate * numerical_derivative(f, self.b2)\n",
    "            self.W3 -= self.learning_rate * numerical_derivative(f, self.W3)\n",
    "            self.b3 -= self.learning_rate * numerical_derivative(f, self.b3)\n",
    "\n",
    "            # 1000 step마다 손실 출력\n",
    "            if step % 1000 == 0:\n",
    "                print(f\"{self.name} step = {step}, loss = {self.loss_val()}\")\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        # 입력 데이터를 2차원으로 reshape (1, 2)\n",
    "        x = input_data.reshape(1, -1)\n",
    "\n",
    "        # 순전파 계산\n",
    "        z2 = np.dot(x, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        y = a3 = sigmoid(z3)  # 최종 출력 확률\n",
    "\n",
    "        # 확률을 0 또는 1로 이진 분류\n",
    "        result = 1 if y > 0.5 else 0\n",
    "\n",
    "        return y, result  # 확률값, 분류결과 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a614e68-f74d-4401-ad39-72002a273f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR step = 0, loss = 4.426675866848697\n",
      "XOR step = 1000, loss = 2.766439303683773\n",
      "XOR step = 2000, loss = 2.7562137135024507\n",
      "XOR step = 3000, loss = 2.730715539267342\n",
      "XOR step = 4000, loss = 2.6666802484442913\n",
      "XOR step = 5000, loss = 2.5254541848523337\n",
      "XOR step = 6000, loss = 2.2894869646408904\n",
      "XOR step = 7000, loss = 2.0125836248392814\n",
      "XOR step = 8000, loss = 1.713488806820763\n",
      "XOR step = 9000, loss = 1.372151704384752\n",
      "XOR step = 10000, loss = 1.0459822849250826\n",
      "XOR step = 11000, loss = 0.7946064002029839\n",
      "XOR step = 12000, loss = 0.6128216037365363\n",
      "XOR step = 13000, loss = 0.47990913886674735\n",
      "XOR step = 14000, loss = 0.3814596860081468\n",
      "XOR step = 15000, loss = 0.30816733055666806\n",
      "XOR step = 16000, loss = 0.25319307581615197\n",
      "XOR step = 17000, loss = 0.21142366214516056\n",
      "XOR step = 18000, loss = 0.17917481504370394\n",
      "XOR step = 19000, loss = 0.15385823531165616\n",
      "XOR step = 20000, loss = 0.13366786921476195\n"
     ]
    }
   ],
   "source": [
    "xdata = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata = np.array([0,1,1,0])\n",
    "xor_obj = LogicGate(\"XOR\", xdata, tdata)\n",
    "xor_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16ae24b4-b62c-4862-87d6-f849bd7fb421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: [0 0], 출력: 0.0373, 판별값: 0\n",
      "입력: [0 1], 출력: 0.9732, 판별값: 1\n",
      "입력: [1 0], 출력: 0.9670, 판별값: 1\n",
      "입력: [1 1], 출력: 0.0343, 판별값: 0\n"
     ]
    }
   ],
   "source": [
    "test_data =np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "for data in test_data:\n",
    "    sigmoid_val, logical_Val =xor_obj.predict(data)\n",
    "    print(f\"입력: {data}, 출력: {sigmoid_val.flatten()[0]:.4f}, 판별값: {logical_Val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "533604c9-3dbc-4cfc-b52a-6fabf3a40f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#은닉층 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7b71eb5-067b-407c-9135-585c99c0180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "        self.name = gate_name  # 게이트 이름 (예: \"XOR\")\n",
    "        self.xdata = xdata.reshape(4, 2)  # 입력 데이터 (4행 2열로 reshape)\n",
    "        self.tdata = tdata.reshape(4, 1)  # 정답 레이블 (4행 1열)\n",
    "\n",
    "        # 입력층(2) → 은닉층1(6) 가중치 및 편향 초기화\n",
    "        self.W2 = np.random.rand(2, 6)     # 입력 노드 2개 → 은닉층1 노드 6개\n",
    "       # print(\"입력층 입력노도\" , self.W2)\n",
    "        self.b2 = np.random.rand(6)        # 은닉층1 편향 (노드 수 6개)\n",
    "       # print(\"입력층 출력 노도\" , self.b2)\n",
    "        \n",
    "        # 은닉층1(6) → 은닉층2(2) 가중치 및 편향 초기화\n",
    "        self.W3 = np.random.rand(6, 2)     # 은닉층1 노드 6개 → 은닉층2 노드 2개\n",
    "      #  print(\"은닉층-1 출력 노도\" , self.W3)\n",
    "        self.b3 = np.random.rand(2)        # 은닉층2 편향 (노드 수 2개)\n",
    "      #  print(\"은닉층-1 출력 노도\" , self.b3)\n",
    "        \n",
    "        # 은닉층2(2) → 출력층(1) 가중치 및 편향 초기화\n",
    "        self.W4 = np.random.rand(2, 1)     # 은닉층2 노드 2개 → 출력 노드 1개\n",
    "      #  print(\"은닉층 입력 노도\" , self.W4)\n",
    "        self.b4 = np.random.rand(1)        # 출력층 편향 (노드 수 1개)\n",
    "       # print(\"은닉층 출력 노도\" , self.W4)\n",
    "        \n",
    "        self.learning_rate = 1e-2         # 학습률 설정\n",
    "\n",
    "    def loss_val(self):\n",
    "        delta = 1e-7  # log 계산 시 0으로 인한 오류 방지용\n",
    "\n",
    "        # 순전파: 입력 → 은닉층1 → 은닉층2 → 출력\n",
    "        z2 = np.dot(self.xdata, self.W2) + self.b2  # 은닉층1의 입력 계산\n",
    "        a2 = sigmoid(z2)                            # 은닉층1의 출력 (활성화)\n",
    "\n",
    "        z3 = np.dot(a2, self.W3) + self.b3          # 은닉층2의 입력 계산\n",
    "        a3 = sigmoid(z3)                            # 은닉층2의 출력 (활성화)\n",
    "\n",
    "        z4 = np.dot(a3, self.W4) + self.b4          # 출력층 입력 계산\n",
    "        y = sigmoid(z4)                             # 최종 출력 계산\n",
    "\n",
    "        # 교차 엔트로피 손실 함수\n",
    "        return -np.sum(\n",
    "            self.tdata * np.log(y + delta) + \n",
    "            (1 - self.tdata) * np.log(1 - y + delta)\n",
    "        )\n",
    "\n",
    "    def train(self):\n",
    "        f = lambda x: self.loss_val()  # 손실 함수를 미분하기 위한 람다\n",
    "\n",
    "        for step in range(50001):  \n",
    "            # 수치 미분을 이용한 가중치 및 편향 업데이트\n",
    "            self.W2 -= self.learning_rate * numerical_derivative(f, self.W2)\n",
    "            self.b2 -= self.learning_rate * numerical_derivative(f, self.b2)\n",
    "            self.W3 -= self.learning_rate * numerical_derivative(f, self.W3)\n",
    "            self.b3 -= self.learning_rate * numerical_derivative(f, self.b3)\n",
    "            self.W4 -= self.learning_rate * numerical_derivative(f, self.W4)\n",
    "            self.b4 -= self.learning_rate * numerical_derivative(f, self.b4)\n",
    "\n",
    "            # 일정 주기마다 손실 출력\n",
    "            if step % 10000 == 0:\n",
    "                print(f\"{self.name} step = {step}, loss = {self.loss_val()}\")\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        # 입력 데이터를 1행 2열로 reshape\n",
    "        self.xdata = input_data\n",
    "\n",
    "        # 순전파 계산 (입력층 → 은닉층1 → 은닉층2 → 출력층)\n",
    "        z2 = np.dot(self.xdata, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "\n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        a3 = sigmoid(z3)\n",
    "\n",
    "        z4 = np.dot(a3, self.W4) + self.b4\n",
    "        y = sigmoid(z4)\n",
    "\n",
    "        # 출력값을 기준으로 논리값(0 또는 1) 결정\n",
    "        result = 1 if y > 0.5 else 0\n",
    "        return y, result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ac473f-a7c4-4f04-8bed-8a2eefb49c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR step = 0, loss = 3.7579897462404865\n",
      "XOR step = 10000, loss = 2.7767957995116945\n",
      "XOR step = 20000, loss = 2.771549695090852\n",
      "XOR step = 30000, loss = 2.7715119680231584\n",
      "XOR step = 40000, loss = 2.771495802399211\n"
     ]
    }
   ],
   "source": [
    "xdata = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata = np.array([0,1,1,0])\n",
    "xor_obj = LogicGate(\"XOR\", xdata, tdata)\n",
    "xor_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9cec7dbd-2f7d-4379-858d-1a9391a4064c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: [0 0], 출력: 0.0386, 판별값: 0\n",
      "입력: [0 1], 출력: 0.9441, 판별값: 1\n",
      "입력: [1 0], 출력: 0.9416, 판별값: 1\n",
      "입력: [1 1], 출력: 0.0801, 판별값: 0\n"
     ]
    }
   ],
   "source": [
    "test_data =np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "for data in test_data:\n",
    "    sigmoid_val, logical_Val =xor_obj.predict(data)\n",
    "    print(f\"입력: {data}, 출력: {sigmoid_val.flatten()[0]:.4f}, 판별값: {logical_Val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2669d87b-195a-465b-9589-c96e294b4f79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
